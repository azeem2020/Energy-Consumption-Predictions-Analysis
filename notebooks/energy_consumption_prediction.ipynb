{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Consumption & Predictions Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The open data set we're using for this demonstration is the hourly power consumption data comes from PJM's website and are in megawatts (MW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data-set Files\n",
    "\n",
    "###### (https://github.com/azeem2020/Energy-Consumption-Predictions-Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Overview\n",
    "This is divided into five parts; they are:\n",
    "<ul>\n",
    "<li>Problem Description</li>\n",
    "<li>Load and Prepare Dataset</li>\n",
    "<li>Model Evaluation</li>\n",
    "<li>Correlation Analysis</li>\n",
    "<li>Develop an Regression Model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Libraries\n",
    "<b><a href='https://numpy.org/'>NumPy</a></b> - <b><a href='https://pandas.pydata.org/'>Pandas</a></b> - <b><a href='https://seaborn.pydata.org/'>Seaborn</a></b> - <b><a href='https://xgboost.readthedocs.io/en/latest/'>XGBoost</a></b>  - <b><a href='https://matplotlib.org/'>Matplotlib</a></b> \n",
    "\n",
    "Let’s get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set\n",
    "We will use hourly power consumption data from <a href='https://www.pjm.com/'>PJM</a> East, it contain data from 2002-2018 for the entire east region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd() # Get current work directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\azeem\\\\Documents\\\\GitHub Repositories\\\\Energy-Consumption-Predictions-Analysis')  # Provide the new path here\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pjme_df = pd.read_csv('data/PJM/hourly-energy-consumption/PJME_hourly.csv', parse_dates=[0], index_col=[0])\n",
    "pjme_df = pjme_df.loc[~pjme_df.index.duplicated(keep='first')].sort_index().dropna()\n",
    "pjme_df.head() # top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dimensionality of the DataFrame\n",
    "Return a tuple representing the dimensionality of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pjme_df.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate summarize descriptive Statistics\n",
    "###### pandas.DataFrame.describe\n",
    "Generate descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding <i>NaN</i> values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pjme_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = pjme_df.plot.hist(figsize=(13, 7), bins=200, title='Distribution of Electricity Power Consumption')\n",
    "plt.xlabel('Power (kWatt)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### View City Aattributes CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_attributes = pd.read_csv('data/PJM/historical-hourly-weather-data/humidity.csv', nrows= 0)\n",
    "city_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'New York'\n",
    "humidity = pd.read_csv('data/PJM/historical-hourly-weather-data/humidity.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('humidity')\n",
    "pressure = pd.read_csv('data/PJM/historical-hourly-weather-data/pressure.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('pressure')\n",
    "temperature = pd.read_csv('data/PJM/historical-hourly-weather-data/temperature.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('temperature')\n",
    "wind_direction = pd.read_csv('data/PJM/historical-hourly-weather-data/wind_direction.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('wind_direction')\n",
    "wind_speed = pd.read_csv('data/PJM/historical-hourly-weather-data/wind_speed.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('wind_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Power and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.concat([temperature, humidity, pressure, wind_direction, wind_speed], axis=1).sort_index()\n",
    "weather_df = weather_df.loc[~weather_df.index.duplicated(keep='first')].sort_index().dropna()\n",
    "weather_df = weather_df.assign(pressure_log = weather_df.pressure.apply(np.log))\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = pd.concat([pjme_df.loc[weather_df.index[0]:weather_df.index[-1]], weather_df], axis=1).sort_index().dropna()\n",
    "\n",
    "comb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power and weather data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(20,15))\n",
    "axes[0].set_title('PJME Power Consumption')\n",
    "axes[0].set_ylabel('Power(MW)')\n",
    "axes[0].set_xlabel('Datetime - Year')\n",
    "comb_df.PJME_MW.plot(ax=axes[0])\n",
    "\n",
    "axes[1].set_title('Temperature')\n",
    "axes[1].set_ylabel('Temperature(K)')\n",
    "axes[1].set_xlabel('Datetime - Year')\n",
    "comb_df.temperature.plot(ax=axes[1])\n",
    "\n",
    "axes[2].set_title('Pressure')\n",
    "axes[2].set_ylabel('Pressure')\n",
    "axes[2].set_xlabel('Datetime - Year')\n",
    "comb_df.pressure.plot(ax=axes[2])\n",
    "\n",
    "axes[3].set_title('Pressure_log')\n",
    "axes[3].set_ylabel('Pressure_log')\n",
    "axes[3].set_xlabel('Datetime - Year')\n",
    "comb_df.pressure_log.plot(ax=axes[3])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig = plt.figure()\n",
    "plt.savefig(\"Image.png\") # save as png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = (comb_df.assign( day_of_week = comb_df.index.dayofweek\n",
    "                            ,year = comb_df.index.year\n",
    "                            ,month = comb_df.index.month\n",
    "                            ,day = comb_df.index.day\n",
    "                            ,day_of_year = comb_df.index.dayofyear\n",
    "\n",
    "                            ,week = comb_df.index.week\n",
    "                            ,week_day = comb_df.index.weekday_name \n",
    "                            ,quarter = comb_df.index.quarter\n",
    "                            ,hour = comb_df.index.hour\n",
    "                            ,hour_x = np.sin(2.*np.pi*comb_df.index.hour/24.)\n",
    "                            ,hour_y = np.cos(2*np.pi*comb_df.index.hour/24.)\n",
    "                            ,day_of_year_x = np.sin(2.*np.pi*comb_df.index.dayofyear/365.)\n",
    "                            ,day_of_year_y = np.cos(2.*np.pi*comb_df.index.dayofyear/365.)\n",
    "                            )\n",
    "            )\n",
    "\n",
    "# df['hourfloat']=df.hour+df.minute/60.0\n",
    "# df['x']=np.sin(2.*np.pi*df.hourfloat/24.)\n",
    "# df['y']=np.cos(2.*np.pi*df.hourfloat/24.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (18,8))\n",
    "corr = final_df.corr()\n",
    "ax = sns.heatmap(corr, annot=True,\n",
    "            xticklabels = corr.columns.values,\n",
    "            yticklabels = corr.columns.values)\n",
    "plt.show()\n",
    "\n",
    "#final_df.corr().round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Power consumption</b> is highly correlated to the <b>hour</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series (Shifting/Lagging)\n",
    "A Time series is a collection of data points indexed, listed or graphed in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time.Thus it is a sequence of discrete-time data.\n",
    "#### Lagging features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lagged weather predictors.\n",
    "# lagged_df = comb_df.loc[comb_df.index.min().ceil('D'):].copy()\n",
    "lagged_df = final_df.copy()\n",
    "\n",
    "# Next day's load values.\n",
    "lagged_df['load_tomorrow'] = lagged_df['PJME_MW'].shift(-24)    \n",
    "\n",
    "for day in range(8):\n",
    "    lagged_df['temperature_d' + str(day)] = lagged_df.temperature.shift(24*day)\n",
    "    lagged_df['wind_speed_d' + str(day)] = lagged_df.wind_speed.shift(24*day)\n",
    "    lagged_df['humidity_d' + str(day)] = lagged_df.humidity.shift(24*day)\n",
    "    lagged_df['pressure_log_d' + str(day)] = lagged_df.pressure_log.shift(24*day)\n",
    "\n",
    "    \n",
    "    \n",
    "    lagged_df['load_d' + str(day)] = lagged_df.PJME_MW.shift(24*day)\n",
    "\n",
    "     \n",
    "lagged_df = lagged_df.dropna()\n",
    "    \n",
    "\n",
    "lagged_df = lagged_df.drop(columns=['temperature', 'wind_speed', 'humidity', 'pressure', 'wind_direction', 'week_day','PJME_MW'])\n",
    "# lagged_df.iloc[50:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lagged_df.drop(columns=['load_tomorrow'])\n",
    "y = lagged_df['load_tomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(actual, prediction, start_date, end_date, title, prediction_label):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.title(title)\n",
    "    plt.plot(y_test.index, y_test, label='Actual')\n",
    "    plt.plot(y_test.index, prediction, label=prediction_label)\n",
    "    plt.ylabel('Power(MW)')\n",
    "    plt.xlabel('Datetime')\n",
    "    plt.legend()\n",
    "    plt.xlim(left= start_date, right=end_date)\n",
    "    plt.show()\n",
    "    \n",
    "def subplot_prediction(actual, prediction,prediction_label):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(20, 15))\n",
    "    \n",
    "    con_df = pd.concat([actual.rename('Actual'),pd.DataFrame(prediction, index=actual.index, columns=[prediction_label])], axis=1)\n",
    "    axes[0].set_title('Actual vs Prediction - One day')\n",
    "    axes[0].set_ylabel('Power(MW)')\n",
    "    axes[0].set_xlabel('Datetime')\n",
    "    con_df.plot(ax=axes[0])\n",
    "    axes[0].set_xlim(left=con_df.index[-24*1] , right=con_df.index[-1])\n",
    "    \n",
    "    axes[1].set_title('Actual vs Prediction - One week')\n",
    "    axes[1].set_ylabel('Power(MW)')\n",
    "    axes[1].set_xlabel('Datetime')\n",
    "    con_df.plot(ax=axes[1])\n",
    "    axes[1].set_xlim(left=actual.index[-24*7] , right=actual.index[-1])\n",
    "    \n",
    "    axes[2].set_title('Actual vs Prediction - One month')\n",
    "    axes[2].set_ylabel('Power(MW)')\n",
    "    axes[2].set_xlabel('Datetime')\n",
    "    con_df.plot(ax=axes[2])\n",
    "    axes[2].set_xlim(left=actual.index[-24*7*4] , right=actual.index[-1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_feature_importances( clf, X_train, y_train=None\n",
    "                             ,top_n=10, figsize=(10,18), print_table=False, title=\"Feature Importances\"):\n",
    "    feat_imp = pd.DataFrame({'importance':clf.feature_importances_})    \n",
    "    feat_imp['feature'] = X_train.columns\n",
    "    feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "    feat_imp = feat_imp.iloc[:top_n]\n",
    "    \n",
    "    feat_imp.sort_values(by='importance', inplace=True)\n",
    "    feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "    feat_imp.plot.barh(title=title, figsize=figsize)\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.show()\n",
    "    \n",
    "    if print_table:\n",
    "        from IPython.display import display\n",
    "        print(\"Top {} features in descending order of importance\".format(top_n))\n",
    "        display(feat_imp.sort_values(by='importance', ascending=False))\n",
    "        \n",
    "    return feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "scores = cross_val_score(reg, X.values, y.values, cv=tscv\n",
    "                         ,scoring='explained_variance'\n",
    "                        )\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() ))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train,y_train)\n",
    "prediction = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_feature_importances(reg, X_train, y_train, top_n=X_train.shape[1], title=reg.__class__.__name__, print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(date, comb_df):\n",
    "    features = comb_df.loc[date]\n",
    "    features = (features.assign(\n",
    "                                day_of_week = features.index.dayofweek\n",
    "                                ,year = features.index.year\n",
    "                                ,month = features.index.month\n",
    "                                ,day = features.index.day\n",
    "                                ,day_of_year = features.index.dayofyear\n",
    "                                ,week = features.index.week\n",
    "#                                             ,week_day = features.index.weekday_name \n",
    "                                ,quarter = features.index.quarter\n",
    "                                ,hour = features.index.hour\n",
    "                                ,hour_x = np.sin(2.*np.pi*features.index.hour/24.)\n",
    "                                ,hour_y = np.cos(2*np.pi*features.index.hour/24.)\n",
    "                                ,day_of_year_x = np.sin(2.*np.pi*features.index.dayofyear/365.)\n",
    "                                ,day_of_year_y = np.cos(2.*np.pi*features.index.dayofyear/365.)\n",
    "                                \n",
    "                                ))\n",
    "    \n",
    "    for day in range(8):\n",
    "        features['temperature_d' + str(day)] = comb_df.temperature.shift(24*day)\n",
    "        features['wind_speed_d' + str(day)] = comb_df.wind_speed.shift(24*day)\n",
    "        features['humidity_d' + str(day)] = comb_df.humidity.shift(24*day)\n",
    "        features['pressure_log_d' + str(day)] = comb_df.pressure_log.shift(24*day)\n",
    "\n",
    "\n",
    "\n",
    "        features['load_d' + str(day)] = comb_df.PJME_MW.shift(24*day)\n",
    "\n",
    "    features = features.dropna()\n",
    "    \n",
    "    features = features.drop(columns=['temperature', 'wind_speed', 'humidity', 'pressure', 'wind_direction','PJME_MW'])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2017-05-01'\n",
    "\n",
    "\n",
    "prediction = reg.predict(get_features(date, comb_df))\n",
    "idx = comb_df.PJME_MW.loc[date].index \n",
    "\n",
    "\n",
    "def plot_prediction_multistep(actual, prediction, start_date, title, prediction_label):\n",
    "    date_rng = pd.date_range(start=start_date, periods=24, freq='H')\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.title(title)\n",
    "    plt.plot(actual.index, actual, label='Actual')\n",
    "    plt.plot(actual.index, prediction, label=prediction_label)\n",
    "    plt.ylabel('Power(MW)')\n",
    "    plt.xlabel('Datetime')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_prediction_multistep(actual=comb_df.PJME_MW.loc[date],prediction=prediction, start_date=date, title='Multistep prediction - 24 hours a head',\n",
    "                prediction_label='ExtraTrees Regressor model prediction')    \n",
    "    \n",
    "    \n",
    "\n",
    "# fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(20, 15))\n",
    "    \n",
    "# con_df = pd.concat([actual.rename('Actual'),pd.DataFrame(prediction, index=actual.index, columns=[prediction_label])], axis=1)\n",
    "# axes[0].set_title('Actual vs Prediction - One day')\n",
    "# axes[0].set_ylabel('Power(MW)')\n",
    "# axes[0].set_xlabel('Datetime')\n",
    "# con_df.plot(ax=axes[0])\n",
    "# axes[0].set_xlim(left=con_df.index[-24*1] , right=con_df.index[-1])\n",
    "\n",
    "# axes[1].set_title('Actual vs Prediction - One week')\n",
    "# axes[1].set_ylabel('Power(MW)')\n",
    "# axes[1].set_xlabel('Datetime')\n",
    "# con_df.plot(ax=axes[1])\n",
    "# axes[1].set_xlim(left=actual.index[-24*7] , right=actual.index[-1])\n",
    "\n",
    "# axes[2].set_title('Actual vs Prediction - One month')\n",
    "# axes[2].set_ylabel('Power(MW)')\n",
    "# axes[2].set_xlabel('Datetime')\n",
    "# con_df.plot(ax=axes[2])\n",
    "# axes[2].set_xlim(left=actual.index[-24*7*4] , right=actual.index[-1])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns = ['PJME_MW','week_day'])\n",
    "y = final_df['PJME_MW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "scores = cross_val_score(reg, X.values, y.values, cv=tscv\n",
    "                         ,scoring='explained_variance'\n",
    "                        )\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() ))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train,y_train)\n",
    "prediction = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_importance(reg, height=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_prediction(y_test, prediction,prediction_label='XGB model prediction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
